import requests
import pandas as pd
import datetime as dt
import time
import os
import streamlit as st

def get_rank(kw, cid, sec):
    """ë„¤ì´ë²„ ì‡¼í•‘ API ìˆ˜ì§‘"""
    try:
        headers = {"X-Naver-Client-Id": cid, "X-Naver-Client-Secret": sec}
        params = {"query": kw, "display": 100, "sort": "sim"}
        res = requests.get("https://openapi.naver.com/v1/search/shop.json", 
                           headers=headers, params=params, timeout=10)
        return res.json().get('items', []) if res.status_code == 200 else []
    except: return []

def run_automation():
    # 1. ì‹œí¬ë¦¿ì—ì„œ 90ê°œ í‚¤ì›Œë“œ ë° API í‚¤ ë¡œë“œ
    try:
        naver_cid = st.secrets["NAVER_CLIENT_ID"]
        naver_csec = st.secrets["NAVER_CLIENT_SECRET"]
        raw_keywords = st.secrets["DEFAULT_KEYWORDS"]
        # ì½¤ë§ˆë‚˜ ì¤„ë°”ê¿ˆìœ¼ë¡œ ì„ì—¬ìˆì–´ë„ ì˜ ì½ì–´ì˜¤ë„ë¡ ì²˜ë¦¬
        keywords = [k.strip() for k in raw_keywords.replace('\n', ',').split(',') if k.strip()]
        
        brand1 = [x.strip() for x in st.secrets.get("MY_BRAND_1", "").split(',')]
        brand2 = [x.strip() for x in st.secrets.get("MY_BRAND_2", "").split(',')]
        my_brands = [b.replace(" ", "") for b in (brand1 + brand2) if b]
    except Exception as e:
        print(f"ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    today = dt.date.today().isoformat()
    daily_results = []

    # 2. 90ê°œ í‚¤ì›Œë“œ ìˆœíšŒí•˜ë©° ì¡°ì‚¬
    print(f"ğŸš€ {len(keywords)}ê°œ í‚¤ì›Œë“œ ì¡°ì‚¬ ì‹œì‘...")
    for idx, kw in enumerate(keywords):
        items = get_rank(kw, naver_cid, naver_csec)
        rank_found = 999 # ìˆœìœ„ ë°– ê¸°ë³¸ê°’
        
        if items:
            for r, item in enumerate(items, 1):
                mall_name = item['mallName'].replace(" ", "")
                if any(brand in mall_name for brand in my_brands):
                    rank_found = r
                    break
        
        daily_results.append({"date": today, "keyword": kw, "rank": rank_found})
        print(f"[{idx+1}/{len(keywords)}] {kw}: {rank_found}ìœ„")
        time.sleep(0.3) # API ì°¨ë‹¨ ë°©ì§€

    # 3. ê¸°ì¡´ ì¥ë¶€ì— 90ê°œ ê²°ê³¼ ì¶”ê°€ ì €ì¥
    file_name = "tracking_log.csv"
    new_df = pd.DataFrame(daily_results)
    
    if os.path.exists(file_name):
        old_df = pd.read_csv(file_name)
        # ì˜ˆì‹œ ë°ì´í„°(ë‚˜ì˜í‚¤ì›Œë“œ)ê°€ ë“¤ì–´ìˆëŠ” ê¸°ì¡´ ë°ì´í„°ëŠ” ì‚­ì œí•˜ê³  ìƒˆë¡œ ì‹œì‘
        old_df = old_df[~old_df['keyword'].isin(["ë‚˜ì˜í‚¤ì›Œë“œ1", "ë‚˜ì˜í‚¤ì›Œë“œ2"])]
        final_df = pd.concat([old_df, new_df], ignore_index=True)
    else:
        final_df = new_df
    
    final_df.drop_duplicates(subset=['date', 'keyword'], keep='last', inplace=True)
    final_df.to_csv(file_name, index=False, encoding='utf-8-sig')
    print("âœ… ëª¨ë“  í‚¤ì›Œë“œ ìˆ˜ì§‘ ì™„ë£Œ!")

if __name__ == "__main__":
    run_automation()
